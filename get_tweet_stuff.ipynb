{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook D:/Github/TweeterPy/get_tweet_stuff.ipynb to script\n",
      "[NbConvertApp] Writing 7574 bytes to D:\\Github\\TweeterPy\\get_tweet_stuff.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script \"D:/Github/TweeterPy/get_tweet_stuff.ipynb\" --no-prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tweeterpy\n",
      "  Downloading tweeterpy-1.0.7-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: six==1.16.0 in d:\\anaconda\\envs\\py3.10\\lib\\site-packages (from tweeterpy) (1.16.0)\n",
      "Requirement already satisfied: idna==3.4 in d:\\anaconda\\envs\\py3.10\\lib\\site-packages (from tweeterpy) (3.4)\n",
      "Requirement already satisfied: lxml==4.9.2 in d:\\anaconda\\envs\\py3.10\\lib\\site-packages (from tweeterpy) (4.9.2)\n",
      "Requirement already satisfied: charset-normalizer==3.1.0 in d:\\anaconda\\envs\\py3.10\\lib\\site-packages (from tweeterpy) (3.1.0)\n",
      "Collecting certifi==2023.7.22\n",
      "  Downloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
      "     -------------------------------------- 158.3/158.3 kB 2.4 MB/s eta 0:00:00\n",
      "Collecting urllib3==2.0.3\n",
      "  Downloading urllib3-2.0.3-py3-none-any.whl (123 kB)\n",
      "     -------------------------------------- 123.6/123.6 kB 7.1 MB/s eta 0:00:00\n",
      "Collecting requests==2.31.0\n",
      "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "     ---------------------------------------- 62.6/62.6 kB 3.3 MB/s eta 0:00:00\n",
      "Collecting bs4==0.0.1\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting demjson3==3.0.6\n",
      "  Downloading demjson3-3.0.6.tar.gz (131 kB)\n",
      "     ---------------------------------------- 131.5/131.5 kB ? eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting Brotli==1.0.9\n",
      "  Downloading Brotli-1.0.9-cp310-cp310-win_amd64.whl (383 kB)\n",
      "     ------------------------------------- 383.3/383.3 kB 12.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: beautifulsoup4==4.12.2 in d:\\anaconda\\envs\\py3.10\\lib\\site-packages (from tweeterpy) (4.12.2)\n",
      "Collecting soupsieve==2.4.1\n",
      "  Downloading soupsieve-2.4.1-py3-none-any.whl (36 kB)\n",
      "Building wheels for collected packages: bs4, demjson3\n",
      "  Building wheel for bs4 (setup.py): started\n",
      "  Building wheel for bs4 (setup.py): finished with status 'done'\n",
      "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1264 sha256=d2732182128ce4eb307d6aa6b37469c51bc8d1fa2eed9b139e92a1836f035100\n",
      "  Stored in directory: c:\\users\\rafit\\appdata\\local\\pip\\cache\\wheels\\e4\\62\\1d\\d4d1bc4f33350ff84227f89b258edb552d604138e3739f5c83\n",
      "  Building wheel for demjson3 (setup.py): started\n",
      "  Building wheel for demjson3 (setup.py): finished with status 'done'\n",
      "  Created wheel for demjson3: filename=demjson3-3.0.6-py3-none-any.whl size=75333 sha256=9855a07f6bb315fee13006b81bfa5dde4b6fac6206ee3e3f44adeff6640b31aa\n",
      "  Stored in directory: c:\\users\\rafit\\appdata\\local\\pip\\cache\\wheels\\bf\\cc\\85\\b97e01da795a059d6e82ca0f77b3da366a51f6c645f12c5a04\n",
      "Successfully built bs4 demjson3\n",
      "Installing collected packages: demjson3, Brotli, urllib3, soupsieve, certifi, requests, bs4, tweeterpy\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.15\n",
      "    Uninstalling urllib3-1.26.15:\n",
      "      Successfully uninstalled urllib3-1.26.15\n",
      "  Attempting uninstall: soupsieve\n",
      "    Found existing installation: soupsieve 2.4\n",
      "    Uninstalling soupsieve-2.4:\n",
      "      Successfully uninstalled soupsieve-2.4\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2022.12.7\n",
      "    Uninstalling certifi-2022.12.7:\n",
      "      Successfully uninstalled certifi-2022.12.7\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.28.2\n",
      "    Uninstalling requests-2.28.2:\n",
      "      Successfully uninstalled requests-2.28.2\n",
      "Successfully installed Brotli-1.0.9 bs4-0.0.1 certifi-2023.7.22 demjson3-3.0.6 requests-2.31.0 soupsieve-2.4.1 tweeterpy-1.0.7 urllib3-2.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install tweeterpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#twitter password  =AJ#~Z+cBUR&7r/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweeterpy import TweeterPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-22 19:33:29,310 [\u001b[0;32mINFO\u001b[0m] :: API Updated Successfully.\n"
     ]
    }
   ],
   "source": [
    "twitter = TweeterPy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# twitter.get_liked_tweets('rngland')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# twitter.get_friends('rngland', following=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"me.json\", \"w\") as a:\n",
    "#     json.dump(twitter.get_user_info('rngland'), a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-22 20:14:40,021 [\u001b[0;32mINFO\u001b[0m] :: User is authenticated.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter.logged_in()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'liked_tweets' from 'liked_tweets' (d:\\Github\\TweeterPy\\liked_tweets.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mliked_tweets\u001b[39;00m \u001b[39mimport\u001b[39;00m liked_tweets\n\u001b[0;32m      2\u001b[0m liked_tweets \u001b[39m=\u001b[39m liked_tweets\u001b[39m.\u001b[39mlocals()\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'liked_tweets' from 'liked_tweets' (d:\\Github\\TweeterPy\\liked_tweets.py)"
     ]
    }
   ],
   "source": [
    "from liked_tweets import liked_tweets\n",
    "liked_tweets = liked_tweets.locals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('liked_tweets.py', 'r') as file:\n",
    "    file_contents = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {}\n",
    "exec(file_contents, my_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "668"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(my_dict['liked']['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1705155679819084179',\n",
       " '1700004016506216614',\n",
       " '1704989552459579398',\n",
       " '1704698971996803138',\n",
       " '1704191384435990713',\n",
       " '1703960491704377476',\n",
       " '1703819665162568007',\n",
       " '1703794209327649001',\n",
       " '1703259351610511574',\n",
       " '1590779807587266561']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rest_ids = []\n",
    "contains_rest_id = my_dict['liked']['data'][i]['content']['itemContent']['tweet_results']['result']\n",
    "for i in range(len(my_dict['liked']['data'])):\n",
    "    if 'rest_id' in my_dict['liked']['data'][i]['content']['itemContent']['tweet_results']['result']:\n",
    "        rest_ids.append(my_dict['liked']['data'][i]['content']['itemContent']['tweet_results']['result']['rest_id'])\n",
    "    \n",
    "rest_ids[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "664"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['2023-09-22 09:42:48',\n",
       " '2023-09-08 04:31:56',\n",
       " '2023-09-21 22:42:41',\n",
       " '2023-09-21 03:28:01',\n",
       " '2023-09-19 17:51:03',\n",
       " '2023-09-19 02:33:33',\n",
       " '2023-09-18 17:13:58',\n",
       " '2023-09-18 15:32:49',\n",
       " '2023-09-17 04:07:29',\n",
       " '2022-11-10 18:53:56']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "created_at = []\n",
    "for i in range(len(my_dict['liked']['data'])):\n",
    "    if 'legacy' in my_dict['liked']['data'][i]['content']['itemContent']['tweet_results']['result']:\n",
    "        created_at.append(datetime.strptime(my_dict['liked']['data'][i]['content']['itemContent']['tweet_results']['result']['legacy']['created_at'], \"%a %b %d %H:%M:%S %z %Y\").strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "len(created_at)\n",
    "created_at[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "664"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['https://pbs.twimg.com/profile_images/1604292546645172224/SL57a00s_normal.png',\n",
       " 'https://pbs.twimg.com/profile_images/1689852229736697856/aQmWl1ku_normal.jpg',\n",
       " 'https://pbs.twimg.com/profile_images/1592599455895031808/VM5FWW47_normal.jpg',\n",
       " 'https://pbs.twimg.com/profile_images/1681138725047136257/5f0aG3LH_normal.jpg',\n",
       " 'https://pbs.twimg.com/profile_images/1347621377503711233/bHg3ipfD_normal.jpg',\n",
       " 'https://pbs.twimg.com/profile_images/1677002315813847040/tdq-LQh1_normal.jpg',\n",
       " 'https://pbs.twimg.com/profile_images/1642647714549710854/QlI3xw3I_normal.jpg',\n",
       " 'https://pbs.twimg.com/profile_images/1639426426494652416/ZQTBrYsc_normal.jpg',\n",
       " 'https://pbs.twimg.com/profile_images/1701107606058921984/cQGzyrh3_normal.jpg',\n",
       " 'https://pbs.twimg.com/profile_images/1563635599906549761/wIum4L8I_normal.jpg']"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile_images = []\n",
    "for i in range(len(my_dict['liked']['data'])):\n",
    "    if 'core' in my_dict['liked']['data'][i]['content']['itemContent']['tweet_results']['result']:\n",
    "        profile_images.append(my_dict['liked']['data'][i]['content']['itemContent']['tweet_results']['result']['core']['user_results']['result']['legacy']['profile_image_url_https'])\n",
    "        \n",
    "len(profile_images)\n",
    "profile_images[0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['=IMAGE(\"https://pbs.twimg.com/profile_images/1604292546645172224/SL57a00s_normal.png\",4 ,45, 45)',\n",
       " '=IMAGE(\"https://pbs.twimg.com/profile_images/1689852229736697856/aQmWl1ku_normal.jpg\",4 ,45, 45)',\n",
       " '=IMAGE(\"https://pbs.twimg.com/profile_images/1592599455895031808/VM5FWW47_normal.jpg\",4 ,45, 45)',\n",
       " '=IMAGE(\"https://pbs.twimg.com/profile_images/1681138725047136257/5f0aG3LH_normal.jpg\",4 ,45, 45)',\n",
       " '=IMAGE(\"https://pbs.twimg.com/profile_images/1347621377503711233/bHg3ipfD_normal.jpg\",4 ,45, 45)',\n",
       " '=IMAGE(\"https://pbs.twimg.com/profile_images/1677002315813847040/tdq-LQh1_normal.jpg\",4 ,45, 45)',\n",
       " '=IMAGE(\"https://pbs.twimg.com/profile_images/1642647714549710854/QlI3xw3I_normal.jpg\",4 ,45, 45)',\n",
       " '=IMAGE(\"https://pbs.twimg.com/profile_images/1639426426494652416/ZQTBrYsc_normal.jpg\",4 ,45, 45)',\n",
       " '=IMAGE(\"https://pbs.twimg.com/profile_images/1701107606058921984/cQGzyrh3_normal.jpg\",4 ,45, 45)',\n",
       " '=IMAGE(\"https://pbs.twimg.com/profile_images/1563635599906549761/wIum4L8I_normal.jpg\",4 ,45, 45)']"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "g_sheet_profile_images = [\"=IMAGE(\\\"\" + profile_images[i] + \"\\\"\" + ',4 ,45, 45)'  for i in range(len(profile_images))]\n",
    "\n",
    "g_sheet_profile_images = [image.replace(\"'\", \"\") for image in g_sheet_profile_images]\n",
    "\n",
    "g_sheet_profile_images[0:10]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "664"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['tdinh_me',\n",
       " 'theJordanNoone',\n",
       " 'mayfer',\n",
       " 'cto_junior',\n",
       " 'gdb',\n",
       " 'space_tintin',\n",
       " 'yacineMTB',\n",
       " 'OODAwiki',\n",
       " 'shakoistsLog',\n",
       " 'kepano']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "screen_names = []\n",
    "for i in range(len(my_dict['liked']['data'])):\n",
    "    if 'core' in my_dict['liked']['data'][i]['content']['itemContent']['tweet_results']['result']:\n",
    "        screen_names.append(my_dict['liked']['data'][i]['content']['itemContent']['tweet_results']['result']['core']['user_results']['result']['legacy']['screen_name'])\n",
    "len(screen_names)\n",
    "screen_names[0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gspread\n",
    "\n",
    "credentials = {\n",
    "    \"installed\": {\n",
    "        \"client_id\": \"117044127800-dg6q9197854uc0g375ul2d7569d8v9mj.apps.googleusercontent.com\",\n",
    "        \"project_id\": \"docs-382418\",\n",
    "        \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n",
    "        \"token_uri\": \"https://oauth2.googleapis.com/token\",\n",
    "        \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n",
    "        \"client_secret\": \"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\",\n",
    "        \"redirect_uris\": [\"http://localhost\"],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=117044127800-dg6q9197854uc0g375ul2d7569d8v9mj.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A58467%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fspreadsheets+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&state=05bqG0Ff4OGn1Nxxb2DSu6OpMKnwHb&access_type=offline\n"
     ]
    }
   ],
   "source": [
    "gc, authorized_user = gspread.oauth_from_dict(credentials)\n",
    "\n",
    "sh = gc.open(\"liked_tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gspread_dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gspread_dataframe import set_with_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "worksheet  = sh.get_worksheet(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_with_dataframe(worksheet, df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len((df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spreadsheetId': '1vVIUT1HnLsaAGIRRJbJqI6Z7kVdmaLwUd7Ei-NkPPHA',\n",
       " 'updatedRange': 'h!A1:F665',\n",
       " 'updatedRows': 665,\n",
       " 'updatedColumns': 6,\n",
       " 'updatedCells': 3990}"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sh.add_worksheet(title='h', rows=len(df), cols=len((df.columns))).update(\n",
    "    [df.columns.values.tolist()] + df.values.tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['liked_tweets']"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worksheet_list = sh.worksheets()\n",
    "worksheet_names = [i.title for i in worksheet_list]\n",
    "worksheet_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_url =['https://twitter.com/' + screen_name[i] + '/status/' + rest_ids[i] for i in range(len(\n",
    "screen_name))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "664"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['My full story: \\n\\nhttps://t.co/SXBdF7Th2B',\n",
       " '@ryxcommar meanwhile the best coders write their powerpoint slides in python with python-pptx and these are not the best coders\\n\\nhttps://t.co/BUN8kuxvJL',\n",
       " 'scammers salivating harder by the hour',\n",
       " '@up_61347132 @sog_on_bird_app @deepfates https://t.co/E4Z85wBMOq',\n",
       " 'Get paid to red team our models, using your domain expertise from a variety of fields: https://t.co/iCQT0otZQe https://t.co/Mod3Fx1F83',\n",
       " 'This book has so much alpha https://t.co/m5p2Y8wiDZ',\n",
       " '@AlcorRespecter https://t.co/LLGhsVVPw2',\n",
       " 'https://t.co/fUFLsQvNDi',\n",
       " \"I want to share my non-rigorous vibes based approach towards data science modeling of data. A lot of my job as a staff data scientist (i'm staff btw) is doing a vibe-check on technical problems, and helping other data scientists from going down an intractable path.\",\n",
       " 'Load up the brain via podcasts, videos, travel, books, conversations. Defrag the brain in nature or in Obsidian.\\n\\nInspiration is the feeling of going from loading to defragging.']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_text = []\n",
    "for i in range(len(my_dict['liked']['data'])):\n",
    "    if 'legacy' in my_dict['liked']['data'][i]['content']['itemContent']['tweet_results']['result']:\n",
    "        full_text.append(my_dict['liked']['data'][i]['content']['itemContent']['tweet_results']['result']['legacy']['full_text'])\n",
    "len(full_text)\n",
    "full_text[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# urls\n",
    "data = {\"rest_ids\" : rest_ids, \"created_at\" : created_at,\"g_sheet_profile_images\" : g_sheet_profile_images ,\"screen_names\" :screen_names ,\"full_text\": full_text,\"tweet_url\": tweet_url}\n",
    "df = pd.DataFrame(data)\n",
    "# df.to_csv('D:/Github/TweeterPy/liked_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rest_ids</th>\n",
       "      <th>created_at</th>\n",
       "      <th>g_sheet_profile_images</th>\n",
       "      <th>screen_names</th>\n",
       "      <th>full_text</th>\n",
       "      <th>tweet_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1705155679819084179</td>\n",
       "      <td>2023-09-22 09:42:48</td>\n",
       "      <td>=IMAGE(\"https://pbs.twimg.com/profile_images/1...</td>\n",
       "      <td>tdinh_me</td>\n",
       "      <td>My full story: \\n\\nhttps://t.co/SXBdF7Th2B</td>\n",
       "      <td>https://twitter.com/tdinh_me/status/1705155679...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1700004016506216614</td>\n",
       "      <td>2023-09-08 04:31:56</td>\n",
       "      <td>=IMAGE(\"https://pbs.twimg.com/profile_images/1...</td>\n",
       "      <td>theJordanNoone</td>\n",
       "      <td>@ryxcommar meanwhile the best coders write the...</td>\n",
       "      <td>https://twitter.com/theJordanNoone/status/1700...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1704989552459579398</td>\n",
       "      <td>2023-09-21 22:42:41</td>\n",
       "      <td>=IMAGE(\"https://pbs.twimg.com/profile_images/1...</td>\n",
       "      <td>mayfer</td>\n",
       "      <td>scammers salivating harder by the hour</td>\n",
       "      <td>https://twitter.com/mayfer/status/170498955245...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1704698971996803138</td>\n",
       "      <td>2023-09-21 03:28:01</td>\n",
       "      <td>=IMAGE(\"https://pbs.twimg.com/profile_images/1...</td>\n",
       "      <td>cto_junior</td>\n",
       "      <td>@up_61347132 @sog_on_bird_app @deepfates https...</td>\n",
       "      <td>https://twitter.com/cto_junior/status/17046989...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1704191384435990713</td>\n",
       "      <td>2023-09-19 17:51:03</td>\n",
       "      <td>=IMAGE(\"https://pbs.twimg.com/profile_images/1...</td>\n",
       "      <td>gdb</td>\n",
       "      <td>Get paid to red team our models, using your do...</td>\n",
       "      <td>https://twitter.com/gdb/status/170419138443599...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>1587867700231081987</td>\n",
       "      <td>2022-11-02 18:02:15</td>\n",
       "      <td>=IMAGE(\"https://pbs.twimg.com/profile_images/1...</td>\n",
       "      <td>NoahTopper</td>\n",
       "      <td>I‚Äôm reading ‚ÄúWhat Computers Still Can‚Äôt Do‚Äù an...</td>\n",
       "      <td>https://twitter.com/NoahTopper/status/15878677...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>1584659361632161792</td>\n",
       "      <td>2022-10-24 21:33:28</td>\n",
       "      <td>=IMAGE(\"https://pbs.twimg.com/profile_images/1...</td>\n",
       "      <td>radshaan</td>\n",
       "      <td>Every single talented engineer (electrical/sof...</td>\n",
       "      <td>https://twitter.com/radshaan/status/1584659361...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>1552124372231458817</td>\n",
       "      <td>2022-07-27 02:51:02</td>\n",
       "      <td>=IMAGE(\"https://pbs.twimg.com/profile_images/1...</td>\n",
       "      <td>BenHanowell</td>\n",
       "      <td>@PhDemetri @baursafi It‚Äôs most popular data ma...</td>\n",
       "      <td>https://twitter.com/BenHanowell/status/1552124...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>1499838567111143431</td>\n",
       "      <td>2022-03-04 20:05:54</td>\n",
       "      <td>=IMAGE(\"https://pbs.twimg.com/profile_images/1...</td>\n",
       "      <td>tyba_latam</td>\n",
       "      <td>¬°Invierte tu dinero, no juegues con √©l! tyba, ...</td>\n",
       "      <td>https://twitter.com/tyba_latam/status/14998385...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>1438120202038829063</td>\n",
       "      <td>2021-09-15 12:39:09</td>\n",
       "      <td>=IMAGE(\"https://pbs.twimg.com/profile_images/3...</td>\n",
       "      <td>waitbutwhy</td>\n",
       "      <td>It's crazy that with an iPhone, a little Starl...</td>\n",
       "      <td>https://twitter.com/waitbutwhy/status/14381202...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>664 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                rest_ids           created_at  \\\n",
       "0    1705155679819084179  2023-09-22 09:42:48   \n",
       "1    1700004016506216614  2023-09-08 04:31:56   \n",
       "2    1704989552459579398  2023-09-21 22:42:41   \n",
       "3    1704698971996803138  2023-09-21 03:28:01   \n",
       "4    1704191384435990713  2023-09-19 17:51:03   \n",
       "..                   ...                  ...   \n",
       "659  1587867700231081987  2022-11-02 18:02:15   \n",
       "660  1584659361632161792  2022-10-24 21:33:28   \n",
       "661  1552124372231458817  2022-07-27 02:51:02   \n",
       "662  1499838567111143431  2022-03-04 20:05:54   \n",
       "663  1438120202038829063  2021-09-15 12:39:09   \n",
       "\n",
       "                                g_sheet_profile_images    screen_names  \\\n",
       "0    =IMAGE(\"https://pbs.twimg.com/profile_images/1...        tdinh_me   \n",
       "1    =IMAGE(\"https://pbs.twimg.com/profile_images/1...  theJordanNoone   \n",
       "2    =IMAGE(\"https://pbs.twimg.com/profile_images/1...          mayfer   \n",
       "3    =IMAGE(\"https://pbs.twimg.com/profile_images/1...      cto_junior   \n",
       "4    =IMAGE(\"https://pbs.twimg.com/profile_images/1...             gdb   \n",
       "..                                                 ...             ...   \n",
       "659  =IMAGE(\"https://pbs.twimg.com/profile_images/1...      NoahTopper   \n",
       "660  =IMAGE(\"https://pbs.twimg.com/profile_images/1...        radshaan   \n",
       "661  =IMAGE(\"https://pbs.twimg.com/profile_images/1...     BenHanowell   \n",
       "662  =IMAGE(\"https://pbs.twimg.com/profile_images/1...      tyba_latam   \n",
       "663  =IMAGE(\"https://pbs.twimg.com/profile_images/3...      waitbutwhy   \n",
       "\n",
       "                                             full_text  \\\n",
       "0           My full story: \\n\\nhttps://t.co/SXBdF7Th2B   \n",
       "1    @ryxcommar meanwhile the best coders write the...   \n",
       "2               scammers salivating harder by the hour   \n",
       "3    @up_61347132 @sog_on_bird_app @deepfates https...   \n",
       "4    Get paid to red team our models, using your do...   \n",
       "..                                                 ...   \n",
       "659  I‚Äôm reading ‚ÄúWhat Computers Still Can‚Äôt Do‚Äù an...   \n",
       "660  Every single talented engineer (electrical/sof...   \n",
       "661  @PhDemetri @baursafi It‚Äôs most popular data ma...   \n",
       "662  ¬°Invierte tu dinero, no juegues con √©l! tyba, ...   \n",
       "663  It's crazy that with an iPhone, a little Starl...   \n",
       "\n",
       "                                             tweet_url  \n",
       "0    https://twitter.com/tdinh_me/status/1705155679...  \n",
       "1    https://twitter.com/theJordanNoone/status/1700...  \n",
       "2    https://twitter.com/mayfer/status/170498955245...  \n",
       "3    https://twitter.com/cto_junior/status/17046989...  \n",
       "4    https://twitter.com/gdb/status/170419138443599...  \n",
       "..                                                 ...  \n",
       "659  https://twitter.com/NoahTopper/status/15878677...  \n",
       "660  https://twitter.com/radshaan/status/1584659361...  \n",
       "661  https://twitter.com/BenHanowell/status/1552124...  \n",
       "662  https://twitter.com/tyba_latam/status/14998385...  \n",
       "663  https://twitter.com/waitbutwhy/status/14381202...  \n",
       "\n",
       "[664 rows x 6 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Today is exactly 2 years since I quit my job and become a full-time indie hacker.'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cards \n",
    "\n",
    "# each element in the list is\n",
    "#  a dictionary. for each dictionary search for title, description, photo_image_full_size_alt_text, thumbnail_image and then get value, string_value and url for photo_image_full_size_alt_text\n",
    "\n",
    "my_dict['liked']['data'][0]['content']['itemContent']['tweet_results']['result']['card']['legacy']['binding_values'][2]['value']['string_value']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to share my non-rigorous vibes based approach towards data science modeling of data. A lot of my job as a staff data scientist (i'm staff btw) is doing a vibe-check on technical problems, and helping other data scientists from going down an intractable path.\n",
      "Indie hacker.\n",
      "\n",
      "üß† @TypingMindApp $30K/mo\n",
      "üì∏ @XnapperHQ $6K/mo\n",
      "üõ† @devutils_app $5.5K/mo\n",
      "ü™Ñ @blackmagic_so (Sold, was $14K/mo)\n",
      "\n",
      "üí¨ https://t.co/9b1SSybSdG\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Today is exactly 2 years since I quit my job and become a full-time indie hacker.'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(my_dict['liked']['data'][8]['content']['itemContent']['tweet_results']['result']['legacy']['full_text'])\n",
    "\n",
    "urls = my_dict['liked']['data'][3]['content']['itemContent']['tweet_results']['result']['legacy']['entities']['urls']\n",
    "\n",
    "for i in urls:\n",
    "    i['expanded_url']\n",
    "\n",
    "# [i for i in urls['expanded_url']]\n",
    "\n",
    "screen_name = my_dict['liked']['data'][0]['content']['itemContent']['tweet_results']['result']['core']['user_results']['result']['legacy']['screen_name']\n",
    "\n",
    "rest_id = my_dict['liked']['data'][0]['content']['itemContent']['tweet_results']['result']['rest_id']\n",
    "\n",
    "'https://twitter.com/' + screen_name + '/status/' + rest_id\n",
    "\n",
    "screen_name\n",
    "rest_id\n",
    "\n",
    "print(my_dict['liked']['data'][0]['content']['itemContent']['tweet_results']['result']['core']['user_results']['result']['legacy']['description'])\n",
    "\n",
    "\n",
    "my_dict['liked']['data'][0]['content']['itemContent']['tweet_results']['result']['legacy']['created_at']\n",
    "\n",
    "#  'in_reply_to_screen_name': 'ryxcommar',\n",
    "# 'in_reply_to_status_id_str': '1700002950012145747',\n",
    "\n",
    "# my_dict['liked']['data'][0]['content']['itemContent']['tweet_results']['result']['core']['user_results']['result']['is_blue_verified']\n",
    "\n",
    "my_dict['liked']['data'][3]['content']['itemContent']['tweet_results']['result']['core']['user_results']['result']['legacy']['profile_image_url_https']\n",
    "\n",
    "\n",
    "my_dict['liked']['data'][0]['content']['itemContent']['tweet_results']['result']['card']['legacy']['binding_values'][2]['value']['string_value']\n",
    "\n",
    "\n",
    "\n",
    "# my_dict['liked']['data'][0]['content']['itemContent']['tweet_results']['result']['card']['legacy']['binding_values']\n",
    "\n",
    "# my_dict['liked']['data'][3]['content']['itemContent']['tweet_results']['result']['card']['legacy']['binding_values'][4]\n",
    "# my_dict['liked']['data'][3]['content']['itemContent']['tweet_results']['result']['card']['legacy']['binding_values'][0]['value']['string_value']\n",
    "\n",
    "\n",
    "# card  \n",
    "    #   {'key': 'title',\n",
    "    #        'value': {'string_value': 'My solopreneur story: zero to $45K/mo in 2 years',\n",
    "    #   {'key': 'description',\n",
    "    #        'value': {'string_value': 'Today is exactly 2 years since I quit my job and become a full-time indie hacker.',\n",
    "        #   {'key': 'photo_image_full_size_alt_text',\n",
    "        #    'value': {'string_value': 'Search over large image datasets with natural language and computer vision! - GitHub - deepfates/memery: Search over large image datasets with natural language and computer vision!',\n",
    "        #      {'key': 'thumbnail_image',\n",
    "        #    'value': {'image_value': {'height': 200,\n",
    "        #      'width': 400,\n",
    "        #      'url': 'https://pbs.twimg.com/card_img/1704513029398745088/aRyYEIOj?format=jpg&name=400x400'},\n",
    "        #     'type': 'IMAGE'}},\n",
    "        ##card "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
