{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tweeterpy\n",
    "# !pip install gspread_dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !jupyter nbconvert --to script \"D:/Github/TweeterPy/get_tweet_stuff.ipynb\" --no-prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "from datetime import datetime\n",
    "# from tweeterpy import TweeterPy\n",
    "#twitter password  =AJ#~Z+cBUR&7r/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gspread_dataframe import set_with_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gspread\n",
    "\n",
    "credentials = {\n",
    "    \"installed\": {\n",
    "        \"client_id\": \"117044127800-dg6q9197854uc0g375ul2d7569d8v9mj.apps.googleusercontent.com\",\n",
    "        \"project_id\": \"docs-382418\",\n",
    "        \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n",
    "        \"token_uri\": \"https://oauth2.googleapis.com/token\",\n",
    "        \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n",
    "        \"client_secret\": \"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\",\n",
    "        \"redirect_uris\": [\"http://localhost\"],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gc, authorized_user = gspread.oauth_from_dict(credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# twitter = TweeterPy()\n",
    "# twitter.get_liked_tweets('rngland')\n",
    "# twitter.get_friends('rngland', following=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('liked_tweets.py', 'r') as file:\n",
    "    file_contents = file.read()\n",
    "my_dict = {}\n",
    "exec(file_contents, my_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_ids = []\n",
    "for i in range(len(my_dict['liked']['data'])):\n",
    "    if 'rest_id' in my_dict['liked']['data'][i]['content']['itemContent']['tweet_results']['result']:\n",
    "        rest_ids.append(my_dict['liked']['data'][i]['content']['itemContent']['tweet_results']['result']['rest_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "created_at = []\n",
    "for i in range(len(my_dict['liked']['data'])):\n",
    "    if 'legacy' in my_dict['liked']['data'][i]['content']['itemContent']['tweet_results']['result']:\n",
    "        created_at.append(datetime.strptime(my_dict['liked']['data'][i]['content']['itemContent']['tweet_results']['result']['legacy']['created_at'], \"%a %b %d %H:%M:%S %z %Y\").strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "664"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['https://pbs.twimg.com/profile_images/1604292546645172224/SL57a00s_normal.png',\n",
       " 'https://pbs.twimg.com/profile_images/1689852229736697856/aQmWl1ku_normal.jpg',\n",
       " 'https://pbs.twimg.com/profile_images/1592599455895031808/VM5FWW47_normal.jpg']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile_images = []\n",
    "for i in range(len(my_dict['liked']['data'])):\n",
    "    if 'core' in my_dict['liked']['data'][i]['content']['itemContent']['tweet_results']['result']:\n",
    "        profile_images.append(my_dict['liked']['data'][i]['content']['itemContent']['tweet_results']['result']['core']['user_results']['result']['legacy']['profile_image_url_https'])\n",
    "        \n",
    "len(profile_images)\n",
    "profile_images[0:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['=IMAGE(\"https://pbs.twimg.com/profile_images/1604292546645172224/SL57a00s_normal.png\",4 ,45, 45)',\n",
       " '=IMAGE(\"https://pbs.twimg.com/profile_images/1689852229736697856/aQmWl1ku_normal.jpg\",4 ,45, 45)',\n",
       " '=IMAGE(\"https://pbs.twimg.com/profile_images/1592599455895031808/VM5FWW47_normal.jpg\",4 ,45, 45)']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_img = [\"=IMAGE(\\\"\" + profile_images[i] + \"\\\"\" + ',4 ,45, 45)'  for i in range(len(profile_images))]\n",
    "\n",
    "p_img = [image.replace(\"'\", \"\") for image in p_img]\n",
    "\n",
    "p_img[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "screen_names = []\n",
    "for i in range(len(my_dict['liked']['data'])):\n",
    "    if 'core' in my_dict['liked']['data'][i]['content']['itemContent']['tweet_results']['result']:\n",
    "        screen_names.append(my_dict['liked']['data'][i]['content']['itemContent']['tweet_results']['result']['core']['user_results']['result']['legacy']['screen_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = []\n",
    "for i in range(len(my_dict['liked']['data'])):\n",
    "    if 'core' in my_dict['liked']['data'][i]['content']['itemContent']['tweet_results']['result']:\n",
    "        name.append(my_dict['liked']['data'][i]['content']['itemContent']['tweet_results']['result']['core']['user_results']['result']['legacy']['name'])\n",
    "# name       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_url =['https://twitter.com/' + i for i in screen_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_text = []\n",
    "for i in range(len(my_dict['liked']['data'])):\n",
    "    if 'legacy' in my_dict['liked']['data'][i]['content']['itemContent']['tweet_results']['result']:\n",
    "        full_text.append(my_dict['liked']['data'][i]['content']['itemContent']['tweet_results']['result']['legacy']['full_text'])           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_url =['https://twitter.com/' + screen_names[i] + '/status/' + rest_ids[i] for i in range(len(\n",
    "screen_names))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "for i in range(len(my_dict['liked']['data'])): \n",
    "    if 'legacy' in my_dict['liked']['data'][i]['content']['itemContent']['tweet_results']['result'] and \\\n",
    "    len(my_dict['liked']['data'][i]['content']['itemContent']['tweet_results']['result']['legacy']['entities']['urls']) >= 1:\n",
    "        urls = my_dict['liked']['data'][i]['content']['itemContent']['tweet_results']['result']['legacy']['entities']['urls']\n",
    "        expanded_urls = [p['expanded_url'] for p in urls]\n",
    "        result.append('  '.join(expanded_urls))\n",
    "    else:\n",
    "        result.append((' '))\n",
    "\n",
    "\n",
    "if len(rest_ids) != len(result): \n",
    "    while len(result) > len(rest_ids) and result[-1] == ' ': \n",
    "        _ = result.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "binding_values = []\n",
    "\n",
    "for i in range(len(my_dict['liked']['data'])):\n",
    "    if 'card' in my_dict['liked']['data'][i]['content']['itemContent']['tweet_results']['result']:\n",
    "        binding_values.append(my_dict['liked']['data'][i]['content']['itemContent']['tweet_results']['result']['card']['legacy']['binding_values'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "card_title = [p['value']['string_value'] for i in binding_values for p in i if p['key'] == 'title']\n",
    "\n",
    "card_description = [p['value']['string_value'] for i in binding_values for p in i if p['key'] == 'description']\n",
    "\n",
    "card_thumbnail_image= [p['value']['image_value']['url'] for i in binding_values for p in i if p['key'] == 'thumbnail_image']\n",
    "\n",
    "card_photo_image_full_size_alt_text = [p['value']['string_value'] for i in binding_values for p in i if p['key'] == 'photo_image_full_size_alt_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rest_ids',\n",
       " 'created_at',\n",
       " 'profile_url',\n",
       " 'p_img',\n",
       " 'screen_names',\n",
       " 'full_text',\n",
       " 'tweet_url',\n",
       " 'result',\n",
       " 'name',\n",
       " 'card_title',\n",
       " 'card_description',\n",
       " 'card_thumbnail_image',\n",
       " 'card_photo_image_full_size_alt_text']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in field_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_names = [\n",
    "\"rest_ids\",\n",
    "\"created_at\",\n",
    "\"profile_url\",\n",
    "\"p_img\",\n",
    "\"screen_names\",\n",
    "\"full_text\",\n",
    "\"tweet_url\",\n",
    "\"result\",\n",
    "\"name\",\n",
    "\"card_title\",\n",
    "\"card_description\",\n",
    "\"card_thumbnail_image\",\n",
    "\"card_photo_image_full_size_alt_text\"\n",
    "]\n",
    "\n",
    "\n",
    "data_dict = {field: eval(field) for field in field_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "664"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "664"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "664"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "664"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "664"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "664"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "664"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "664"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "664"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(rest_ids)\n",
    "len(created_at)\n",
    "len(profile_url)\n",
    "len(p_img)\n",
    "len(screen_names)\n",
    "len(full_text)\n",
    "len(tweet_url)\n",
    "len(result)\n",
    "len(name)\n",
    "len(card_title)\n",
    "len(card_description)\n",
    "len(card_thumbnail_image)\n",
    "len(card_photo_image_full_size_alt_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(data_dict)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\frame.py:664\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    658\u001b[0m     mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_mgr(\n\u001b[0;32m    659\u001b[0m         data, axes\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m: index, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: columns}, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy\n\u001b[0;32m    660\u001b[0m     )\n\u001b[0;32m    662\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mdict\u001b[39m):\n\u001b[0;32m    663\u001b[0m     \u001b[39m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 664\u001b[0m     mgr \u001b[39m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, typ\u001b[39m=\u001b[39;49mmanager)\n\u001b[0;32m    665\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ma\u001b[39m.\u001b[39mMaskedArray):\n\u001b[0;32m    666\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mma\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmrecords\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmrecords\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\internals\\construction.py:493\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    490\u001b[0m         \u001b[39m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    491\u001b[0m         arrays \u001b[39m=\u001b[39m [x\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m arrays]\n\u001b[1;32m--> 493\u001b[0m \u001b[39mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[39m=\u001b[39;49mdtype, typ\u001b[39m=\u001b[39;49mtyp, consolidate\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\internals\\construction.py:118\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    116\u001b[0m     \u001b[39m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 118\u001b[0m         index \u001b[39m=\u001b[39m _extract_index(arrays)\n\u001b[0;32m    119\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m         index \u001b[39m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\internals\\construction.py:666\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    664\u001b[0m lengths \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39m(raw_lengths))\n\u001b[0;32m    665\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(lengths) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 666\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAll arrays must be of the same length\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    668\u001b[0m \u001b[39mif\u001b[39;00m have_dicts:\n\u001b[0;32m    669\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    670\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    671\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data_dict)\n",
    "# df.to_csv('D:/Github/TweeterPy/liked_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh = gc.open(\"liked_tweets\")\n",
    "worksheet  = sh.get_worksheet(0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "worksheet.format(f\"g2:g{len(rest_ids)}\", {\n",
    "  \"textFormat\": {\n",
    "    \"fontSize\": 14\n",
    "   }\n",
    "})\n",
    "set_with_dataframe(worksheet, df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to share my non-rigorous vibes based approach towards data science modeling of data. A lot of my job as a staff data scientist (i'm staff btw) is doing a vibe-check on technical problems, and helping other data scientists from going down an intractable path.\n",
      "Indie hacker.\n",
      "\n",
      "ðŸ§  @TypingMindApp $30K/mo\n",
      "ðŸ“¸ @XnapperHQ $6K/mo\n",
      "ðŸ›  @devutils_app $5.5K/mo\n",
      "ðŸª„ @blackmagic_so (Sold, was $14K/mo)\n",
      "\n",
      "ðŸ’¬ https://t.co/9b1SSybSdG\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Today is exactly 2 years since I quit my job and become a full-time indie hacker.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(my_dict['liked']['data'][8]['content']['itemContent']['tweet_results']['result']['legacy']['full_text'])\n",
    "\n",
    "urls = my_dict['liked']['data'][3]['content']['itemContent']['tweet_results']['result']['legacy']['entities']['urls']\n",
    "\n",
    "for i in urls:\n",
    "    i['expanded_url']\n",
    "\n",
    "# [i for i in urls['expanded_url']]\n",
    "\n",
    "screen_name = my_dict['liked']['data'][0]['content']['itemContent']['tweet_results']['result']['core']['user_results']['result']['legacy']['screen_name']\n",
    "\n",
    "rest_id = my_dict['liked']['data'][0]['content']['itemContent']['tweet_results']['result']['rest_id']\n",
    "\n",
    "'https://twitter.com/' + screen_name + '/status/' + rest_id\n",
    "\n",
    "screen_name\n",
    "rest_id\n",
    "\n",
    "print(my_dict['liked']['data'][0]['content']['itemContent']['tweet_results']['result']['core']['user_results']['result']['legacy']['description'])\n",
    "\n",
    "\n",
    "my_dict['liked']['data'][0]['content']['itemContent']['tweet_results']['result']['legacy']['created_at']\n",
    "\n",
    "#  'in_reply_to_screen_name': 'ryxcommar',\n",
    "# 'in_reply_to_status_id_str': '1700002950012145747',\n",
    "\n",
    "# my_dict['liked']['data'][0]['content']['itemContent']['tweet_results']['result']['core']['user_results']['result']['is_blue_verified']\n",
    "\n",
    "my_dict['liked']['data'][3]['content']['itemContent']['tweet_results']['result']['core']['user_results']['result']['legacy']['profile_image_url_https']\n",
    "\n",
    "\n",
    "my_dict['liked']['data'][0]['content']['itemContent']['tweet_results']['result']['card']['legacy']['binding_values'][2]['value']['string_value']\n",
    "\n",
    "\n",
    "\n",
    "# my_dict['liked']['data'][0]['content']['itemContent']['tweet_results']['result']['card']['legacy']['binding_values']\n",
    "\n",
    "# my_dict['liked']['data'][3]['content']['itemContent']['tweet_results']['result']['card']['legacy']['binding_values'][4]\n",
    "# my_dict['liked']['data'][3]['content']['itemContent']['tweet_results']['result']['card']['legacy']['binding_values'][0]['value']['string_value']\n",
    "\n",
    "\n",
    "# card  \n",
    "    #   {'key': 'title',\n",
    "    #        'value': {'string_value': 'My solopreneur story: zero to $45K/mo in 2 years',\n",
    "    #   {'key': 'description',\n",
    "    #        'value': {'string_value': 'Today is exactly 2 years since I quit my job and become a full-time indie hacker.',\n",
    "        #   {'key': 'photo_image_full_size_alt_text',\n",
    "        #    'value': {'string_value': 'Search over large image datasets with natural language and computer vision! - GitHub - deepfates/memery: Search over large image datasets with natural language and computer vision!',\n",
    "        #      {'key': 'thumbnail_image',\n",
    "        #    'value': {'image_value': {'height': 200,\n",
    "        #      'width': 400,\n",
    "        #      'url': 'https://pbs.twimg.com/card_img/1704513029398745088/aRyYEIOj?format=jpg&name=400x400'},\n",
    "        #     'type': 'IMAGE'}},\n",
    "        ##card "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
